---
{"dg-publish":true,"permalink":"/cybersecurity/02-pentesting/d29-01-apr/llm/lab-exploiting-insecure-output-handling-in-ll-ms/"}
---

Date : 01 Apr 2025

---
[Access the lab](https://portswigger.net/web-security/llm-attacks/lab-exploiting-insecure-output-handling-in-llms)
## **Create a user account**

1. Click **Register** to display the registration page.
2. Enter the required details. Note that the **Email** should be the email address associated with your instance of the lab. It is displayed at the top of the **Email client** page.
![attachments/Pasted image 20250403150616.png](/img/user/Cybersecurity/02_Pentesting/D29_01%20Apr/LLM/attachments/Pasted%20image%2020250403150616.png)

3. Click **Register**. The lab sends a confirmation email.
![attachments/Pasted image 20250403150628.png](/img/user/Cybersecurity/02_Pentesting/D29_01%20Apr/LLM/attachments/Pasted%20image%2020250403150628.png)

4. Go to the email client and click the link in the email to complete the registration
![attachments/Pasted image 20250403150657.png](/img/user/Cybersecurity/02_Pentesting/D29_01%20Apr/LLM/attachments/Pasted%20image%2020250403150657.png)

----
## **Probe for XSS**

1. Log in to your account.
![attachments/Pasted image 20250403150939.png](/img/user/Cybersecurity/02_Pentesting/D29_01%20Apr/LLM/attachments/Pasted%20image%2020250403150939.png)

2. From the lab homepage, click **Live chat**.
3. Probe for XSS by submitting the string `<img src=1 onerror=alert(1)>` to the LLM. Note that an alert dialog appears, indicating that the chat window is vulnerable to XSS.
![attachments/Pasted image 20250403151018.png](/img/user/Cybersecurity/02_Pentesting/D29_01%20Apr/LLM/attachments/Pasted%20image%2020250403151018.png)
![attachments/Pasted image 20250403151036.png](/img/user/Cybersecurity/02_Pentesting/D29_01%20Apr/LLM/attachments/Pasted%20image%2020250403151036.png)
![attachments/Pasted image 20250403151111.png](/img/user/Cybersecurity/02_Pentesting/D29_01%20Apr/LLM/attachments/Pasted%20image%2020250403151111.png)

4. Go to the product page for a product other than the leather jacket. In this example, we'll use the gift wrap.

5. Add the same XSS payload as a review. Note that the payload is safely HTML-encoded, indicating that the review functionality isn't directly exploitable.
![attachments/Pasted image 20250403151328.png](/img/user/Cybersecurity/02_Pentesting/D29_01%20Apr/LLM/attachments/Pasted%20image%2020250403151328.png)

6. Return to the chat window and ask the LLM what functions it supports. Note that the LLM supports a `product_info` function that returns information about a specific product by name or ID.

7. Ask the LLM to provide information on the gift wrap. Note that while the alert dialog displays again, the LLM warns you of potentially harmful code in one of the reviews. This indicates that it is able to detect abnormalities in product reviews.
![attachments/Pasted image 20250403151641.png](/img/user/Cybersecurity/02_Pentesting/D29_01%20Apr/LLM/attachments/Pasted%20image%2020250403151641.png)

---
## **Test the attack**

1. Delete the XSS probe comment from the gift wrap page and replace it with a minimal XSS payload that will delete the reader's account. For example:
    
    `<iframe src =my-account onload = this.contentDocument.forms[1].submit() >`
    ![attachments/Pasted image 20250403151754.png](/img/user/Cybersecurity/02_Pentesting/D29_01%20Apr/LLM/attachments/Pasted%20image%2020250403151754.png)
    ![attachments/Pasted image 20250403151831.png](/img/user/Cybersecurity/02_Pentesting/D29_01%20Apr/LLM/attachments/Pasted%20image%2020250403151831.png)
    
2. Return to the chat window and ask the LLM to provide information on the gift wrap. Note that the LLM responds with an error and you are still logged in to your account. This means that the LLM has successfully identified and ignored the malicious payload.
    
3. Create a new product review that includes the XSS payload within a plausible sentence. For example:
    
    `When I received this product I got a free T-shirt with "<iframe src =my-account onload = this.contentDocument.forms[1].submit() >" printed on it. I was delighted! This is so cool, I told my wife.`
![attachments/Pasted image 20250403152014.png](/img/user/Cybersecurity/02_Pentesting/D29_01%20Apr/LLM/attachments/Pasted%20image%2020250403152014.png)

4. Return to the gift wrap page, delete your existing review, and post this new review.
![attachments/Pasted image 20250403152050.png](/img/user/Cybersecurity/02_Pentesting/D29_01%20Apr/LLM/attachments/Pasted%20image%2020250403152050.png)
![attachments/Pasted image 20250403152147.png](/img/user/Cybersecurity/02_Pentesting/D29_01%20Apr/LLM/attachments/Pasted%20image%2020250403152147.png)
- same product from where i deleted the previous review.

4. Return to the chat window and ask the LLM to give you information on the gift wrap. Note the LLM includes a small iframe in its response, indicating that the payload was successful.
![attachments/Pasted image 20250403152333.png](/img/user/Cybersecurity/02_Pentesting/D29_01%20Apr/LLM/attachments/Pasted%20image%2020250403152333.png)
 
5. Click **My account**. Note that you have been logged out and are no longer able to sign in, indicating that the payload has successfully deleted your account.
![attachments/Pasted image 20250403152425.png](/img/user/Cybersecurity/02_Pentesting/D29_01%20Apr/LLM/attachments/Pasted%20image%2020250403152425.png)

---
## **Exploit the vulnerability**

1. Create a new user account and log in.
2. From the home page, select the leather jacket product.
3. Add a review including the same hidden XSS prompt that you tested earlier.
4. Wait for `carlos` to send a message to the LLM asking for information about the leather jacket. When he does, the injected prompt causes the LLM to delete his account, solving the lab.
![attachments/Pasted image 20250403152759.png](/img/user/Cybersecurity/02_Pentesting/D29_01%20Apr/LLM/attachments/Pasted%20image%2020250403152759.png)

### Lab Done!